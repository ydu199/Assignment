---
title: "Exploring and Tagging Text"
author: "Yu Du"
date: "11/17/2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
#require(devtools)
#devtools::install_github("truenumbers/tnum/tnum")
```

## Loading the required package

```{r}
library(tnum)
library(tidyverse)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
```

## Checking the existing phrase list

```{r}
tnum.authorize(ip="54.158.136.133")
tnum.getDatabasePhraseList("subject", levels=3)
```

## Quering all the sentences with "love" in Sense and Sensibility

```{r}
num1 = tnum.query("*sensibility* has text = REGEXP(\"love\")")
num2 = tnum.query("*sensibility* has text = REGEXP(\"love\")", max = 200)
textdf = tnum.objectsToDf(num2)
```

### Wordcloud for sentences containing "love"

```{r}
docs <- Corpus(VectorSource(num2))
```

```{r}
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
```

```{r}
#convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
```

```{r}
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
```

```{r}
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

### Plot the positions of each sentence containing "love"

```{r}
piclove = tnum.makePhraseGraphFromPathList(textdf$subject)
tnum.plotGraph(piclove, style = "nicely", size = 1000)
```

## Tagging each sentences with reference

```{r}
tnum.tagByQuery("*sensibility* has text = REGEXP(\"love\")", "reference:love")
```

```{r}
num3 = tnum.query("@reference:love", max = 200)
textdf3 = tnum.objectsToDf(num3)
```

## Plot of word "love" by chapters

```{r}
textdf4 = separate(textdf3, col = subject, c("book","chapter","other"), sep = "/", remove = FALSE)
count_love = textdf4 %>% group_by(chapter) %>% summarise(count = n())
count_love = separate(count_love, col = chapter, c("Chapter", "number"), sep = "-", remove = FALSE)
ggplot(count_love, aes(x = number, y = count, color = number)) +
  geom_bar(stat = "identity", fill = "white") +
  labs(x = "Chapter Number", y = "Number of LOVE Appeared", title = "Appearance of LOVE in each Chapter")
```

From the plot we can tell that Chapter 3 in Jane Austen's book Sense and Sensibility contains the most word "love" and Chapter 49 ranks the second. In contrast, Chapter 1, 5, 7, 19, 21, 27, 33, 36, 39, 41, 42, and 48 have the least word "love" appearance. 



References
 
Allen Razdow (2020). tnum: An R Interface for Truenumbers. R package version 0.3.2.

Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686,
  https://doi.org/10.21105/joss.01686
  
Ingo Feinerer and Kurt Hornik (2020). tm: Text Mining Package. R package version 0.7-8.
  https://CRAN.R-project.org/package=tm  
  
Milan Bouchet-Valat (2020). SnowballC: Snowball Stemmers Based on the C 'libstemmer' UTF-8 Library.
  R package version 0.7.0. https://CRAN.R-project.org/package=SnowballC  
  
Ian Fellows (2018). wordcloud: Word Clouds. R package version 2.6.
  https://CRAN.R-project.org/package=wordcloud

Erich Neuwirth (2014). RColorBrewer: ColorBrewer Palettes. R package version 1.1-2.
  https://CRAN.R-project.org/package=RColorBrewer
  
  